{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":102966,"databundleVersionId":12412856,"sourceType":"competition"}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import essential libraries for data handling, image processing, model building, and evaluation\nimport numpy as np\nimport pandas as pd\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.applications import EfficientNetB1\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom PIL import Image\nimport tensorflow as tf\nfrom sklearn.metrics import roc_curve, auc\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:48:17.663121Z","iopub.execute_input":"2025-05-24T10:48:17.663388Z","iopub.status.idle":"2025-05-24T10:48:21.285438Z","shell.execute_reply.started":"2025-05-24T10:48:17.663366Z","shell.execute_reply":"2025-05-24T10:48:21.284856Z"}},"outputs":[{"name":"stderr","text":"2025-05-24 10:48:18.217800: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1748083698.240371      85 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1748083698.247241      85 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Set random seeds for reproducibility\nnp.random.seed(42)\ntf.random.set_seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:48:50.775131Z","iopub.execute_input":"2025-05-24T10:48:50.775881Z","iopub.status.idle":"2025-05-24T10:48:50.779524Z","shell.execute_reply.started":"2025-05-24T10:48:50.775856Z","shell.execute_reply":"2025-05-24T10:48:50.778840Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"# Data path configuration \nTRAIN_IMAGE_DIR = \"/kaggle/input/soil-classification-part-2/soil_competition-2025/train\"           \nTRAIN_LABELS_PATH = \"/kaggle/input/soil-classification-part-2/soil_competition-2025/train_labels.csv\"\nTEST_IMAGE_DIR = \"/kaggle/input/soil-classification-part-2/soil_competition-2025/test\"\nTEST_IDS_PATH = \"/kaggle/input/soil-classification-part-2/soil_competition-2025/test_ids.csv\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:48:56.776868Z","iopub.execute_input":"2025-05-24T10:48:56.777135Z","iopub.status.idle":"2025-05-24T10:48:56.780995Z","shell.execute_reply.started":"2025-05-24T10:48:56.777116Z","shell.execute_reply":"2025-05-24T10:48:56.780330Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Load training labels from CSV \ndf_train_labels = pd.read_csv(TRAIN_LABELS_PATH)\nprint(\"Sample rows from train_labels.csv:\")\nprint(df_train_labels.head())\nprint(f\"\\nLabel distribution (should be all 1s - soil):\")\nprint(df_train_labels['label'].value_counts())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:49:03.724046Z","iopub.execute_input":"2025-05-24T10:49:03.724315Z","iopub.status.idle":"2025-05-24T10:49:03.736291Z","shell.execute_reply.started":"2025-05-24T10:49:03.724294Z","shell.execute_reply":"2025-05-24T10:49:03.735540Z"}},"outputs":[{"name":"stdout","text":"Sample rows from train_labels.csv:\n           image_id  label\n0  img_ed005410.jpg      1\n1  img_0c5ecd2a.jpg      1\n2  img_ed713bb5.jpg      1\n3  img_12c58874.jpg      1\n4  img_eff357af.jpg      1\n\nLabel distribution (should be all 1s - soil):\nlabel\n1    1222\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Load soil images\nsoil_image_paths = []\nmissing_count = 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:49:11.637668Z","iopub.execute_input":"2025-05-24T10:49:11.637942Z","iopub.status.idle":"2025-05-24T10:49:11.641543Z","shell.execute_reply.started":"2025-05-24T10:49:11.637922Z","shell.execute_reply":"2025-05-24T10:49:11.640897Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Verify existence and validity of soil images by iterating over labels,\n# checking if image files exist and can be opened properly,\n# and track corrupted or missing images.\nimport os\nfor idx, row in df_train_labels.iterrows():\n    image_id = row['image_id']         \n    image_path = os.path.join(TRAIN_IMAGE_DIR, image_id)\n    \n    if os.path.exists(image_path):\n        try:\n            with Image.open(image_path) as img:\n                if img.mode in ['RGB', 'L', 'RGBA']:\n                    soil_image_paths.append(image_path)\n        except Exception as e:\n            print(f\"Corrupted image: {image_path}\")\n            missing_count += 1\n    else:\n        print(f\"Warning: {image_path} not found!\")\n        missing_count += 1\n\nprint(f\" Total soil images loaded: {len(soil_image_paths)}\")\nprint(f\" Missing/corrupted images: {missing_count}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:49:31.497798Z","iopub.execute_input":"2025-05-24T10:49:31.498478Z","iopub.status.idle":"2025-05-24T10:49:36.009729Z","shell.execute_reply.started":"2025-05-24T10:49:31.498452Z","shell.execute_reply":"2025-05-24T10:49:36.009100Z"}},"outputs":[{"name":"stdout","text":"\nüìÇ Loading soil images...\n‚úÖ Total soil images loaded: 1218\n‚ùå Missing/corrupted images: 0\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# Split soil images for training and validation \ntrain_paths, val_paths = train_test_split(\n    soil_image_paths,\n    test_size=0.2,\n    random_state=42\n)\n\nprint(f\"\\nüîÑ Dataset split:\")\nprint(f\"   Training soil images: {len(train_paths)}\")\nprint(f\"   Validation soil images: {len(val_paths)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:49:43.220735Z","iopub.execute_input":"2025-05-24T10:49:43.221044Z","iopub.status.idle":"2025-05-24T10:49:43.226911Z","shell.execute_reply.started":"2025-05-24T10:49:43.221021Z","shell.execute_reply":"2025-05-24T10:49:43.226237Z"}},"outputs":[{"name":"stdout","text":"\nüîÑ Dataset split:\n   Training soil images: 974\n   Validation soil images: 244\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"# Image preprocessing \n#  Preprocess images for feature extraction\n\ndef preprocess_images(paths, img_size=(224, 224)):\n    images = []\n    valid_paths = []\n    \n    for path in paths:\n        try:\n            img = Image.open(path).convert('RGB')\n            img = img.resize(img_size, Image.Resampling.LANCZOS)\n            img_array = np.array(img, dtype=np.float32)\n            \n            # EfficientNet preprocessing\n            img_array = tf.keras.applications.efficientnet.preprocess_input(img_array)\n            images.append(img_array)\n            valid_paths.append(path)\n            \n        except Exception as e:\n            print(f\"Error processing {path}: {e}\")\n    \n    return np.array(images), valid_paths","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:50:34.850950Z","iopub.execute_input":"2025-05-24T10:50:34.851229Z","iopub.status.idle":"2025-05-24T10:50:34.856598Z","shell.execute_reply.started":"2025-05-24T10:50:34.851208Z","shell.execute_reply":"2025-05-24T10:50:34.855818Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"# Load and preprocess training images\nX_train, valid_train_paths = preprocess_images(train_paths)\nX_val, valid_val_paths = preprocess_images(val_paths)\n\nprint(f\"Training data shape: {X_train.shape}\")\nprint(f\"Validation data shape: {X_val.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:50:48.343978Z","iopub.execute_input":"2025-05-24T10:50:48.344249Z","iopub.status.idle":"2025-05-24T10:51:01.615409Z","shell.execute_reply.started":"2025-05-24T10:50:48.344230Z","shell.execute_reply":"2025-05-24T10:51:01.614685Z"}},"outputs":[{"name":"stdout","text":"\nüîÑ Preprocessing training images...\nTraining data shape: (974, 224, 224, 3)\nValidation data shape: (244, 224, 224, 3)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"#  Build Feature Extraction Model \n#  Creating a feature extraction model using EfficientNet\n\ndef create_feature_extractor(input_shape=(224, 224, 3)):\n    \n    base_model = EfficientNetB1(\n        include_top=False, \n        weights='imagenet', \n        input_shape=input_shape\n    )\n    \n    # Freeze base model for stable feature extraction\n    base_model.trainable = False\n    \n    # Add feature extraction head\n    x = base_model.output\n    x = GlobalAveragePooling2D()(x)\n    features = Dense(512, activation='relu', name='features')(x)\n    \n    model = Model(inputs=base_model.input, outputs=features)\n    return model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:51:05.397267Z","iopub.execute_input":"2025-05-24T10:51:05.397544Z","iopub.status.idle":"2025-05-24T10:51:05.402341Z","shell.execute_reply.started":"2025-05-24T10:51:05.397523Z","shell.execute_reply":"2025-05-24T10:51:05.401531Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Create feature extractor\nfeature_extractor = create_feature_extractor()\nprint(f\"\\n Feature extractor created with {feature_extractor.count_params():,} parameters\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:51:12.962398Z","iopub.execute_input":"2025-05-24T10:51:12.963077Z","iopub.status.idle":"2025-05-24T10:51:17.353023Z","shell.execute_reply.started":"2025-05-24T10:51:12.963047Z","shell.execute_reply":"2025-05-24T10:51:17.352414Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1748083874.284092      85 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1748083874.284732      85 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"},{"name":"stdout","text":"Downloading data from https://storage.googleapis.com/keras-applications/efficientnetb1_notop.h5\n\u001b[1m27018416/27018416\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n\nüèó Feature extractor created with 7,231,111 parameters\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Extract features from soil images \nprint(\"\\nüîç Extracting features from soil images...\")\ntrain_features = feature_extractor.predict(X_train, batch_size=32, verbose=1)\nval_features = feature_extractor.predict(X_val, batch_size=32, verbose=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:51:20.326397Z","iopub.execute_input":"2025-05-24T10:51:20.326676Z","iopub.status.idle":"2025-05-24T10:51:53.043855Z","shell.execute_reply.started":"2025-05-24T10:51:20.326657Z","shell.execute_reply":"2025-05-24T10:51:53.043082Z"}},"outputs":[{"name":"stdout","text":"\nüîç Extracting features from soil images...\n","output_type":"stream"},{"name":"stderr","text":"WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nI0000 00:00:1748083886.440403     147 service.cc:148] XLA service 0x7967e40041e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\nI0000 00:00:1748083886.441517     147 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\nI0000 00:00:1748083886.441537     147 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\nI0000 00:00:1748083887.400517     147 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m 3/31\u001b[0m \u001b[32m‚îÅ\u001b[0m\u001b[37m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[1m1s\u001b[0m 61ms/step","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1748083894.166850     147 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m31/31\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 398ms/step\n\u001b[1m8/8\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 893ms/step\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"print(f\"Training features shape: {train_features.shape}\")\nprint(f\"Validation features shape: {val_features.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:51:58.432800Z","iopub.execute_input":"2025-05-24T10:51:58.433559Z","iopub.status.idle":"2025-05-24T10:51:58.437878Z","shell.execute_reply.started":"2025-05-24T10:51:58.433535Z","shell.execute_reply":"2025-05-24T10:51:58.436999Z"}},"outputs":[{"name":"stdout","text":"Training features shape: (974, 512)\nValidation features shape: (244, 512)\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"#  Compute mean and covariance of soil features\n\ndef compute_soil_statistics(features):\n    soil_mean = np.mean(features, axis=0)\n    soil_cov = np.cov(features.T)\n    \n    # Add small regularization to covariance matrix\n    soil_cov += np.eye(soil_cov.shape[0]) * 1e-6\n    \n    return soil_mean, soil_cov\n\nsoil_mean, soil_cov = compute_soil_statistics(train_features)\nprint(f\"\\nüìä Soil statistics computed:\")\nprint(f\"   Mean feature vector shape: {soil_mean.shape}\")\nprint(f\"   Covariance matrix shape: {soil_cov.shape}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:52:16.394800Z","iopub.execute_input":"2025-05-24T10:52:16.395293Z","iopub.status.idle":"2025-05-24T10:52:16.430890Z","shell.execute_reply.started":"2025-05-24T10:52:16.395269Z","shell.execute_reply":"2025-05-24T10:52:16.430130Z"}},"outputs":[{"name":"stdout","text":"\nüìä Soil statistics computed:\n   Mean feature vector shape: (512,)\n   Covariance matrix shape: (512, 512)\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# Define anomaly detection functions \n#  Compute Mahalanobis distance from soil prototype\n\ndef mahalanobis_distance(features, mean, cov):\n    try:\n        cov_inv = np.linalg.inv(cov)\n    except:\n        cov_inv = np.linalg.pinv(cov)\n    \n    diff = features - mean\n    distances = np.array([np.sqrt(np.dot(np.dot(d, cov_inv), d.T)) for d in diff])\n    return distances","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:52:24.664559Z","iopub.execute_input":"2025-05-24T10:52:24.664871Z","iopub.status.idle":"2025-05-24T10:52:24.669771Z","shell.execute_reply.started":"2025-05-24T10:52:24.664852Z","shell.execute_reply":"2025-05-24T10:52:24.668947Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"# Compute Euclidean distance from soil prototype\ndef euclidean_distance(features, mean):\n    distances = np.linalg.norm(features - mean, axis=1)\n    return distances","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:52:37.363546Z","iopub.execute_input":"2025-05-24T10:52:37.363858Z","iopub.status.idle":"2025-05-24T10:52:37.367723Z","shell.execute_reply.started":"2025-05-24T10:52:37.363838Z","shell.execute_reply":"2025-05-24T10:52:37.366954Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"#Compute cosine similarity with soil prototype\ndef cosine_similarity_score(features, mean):\n    # Normalize vectors\n    features_norm = features / (np.linalg.norm(features, axis=1, keepdims=True) + 1e-8)\n    mean_norm = mean / (np.linalg.norm(mean) + 1e-8)\n    \n    similarities = np.dot(features_norm, mean_norm)\n    return similarities","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:52:43.384065Z","iopub.execute_input":"2025-05-24T10:52:43.384706Z","iopub.status.idle":"2025-05-24T10:52:43.388400Z","shell.execute_reply.started":"2025-05-24T10:52:43.384685Z","shell.execute_reply":"2025-05-24T10:52:43.387689Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"# Compute baseline distances on training data \n\ntrain_mahal_dist = mahalanobis_distance(train_features, soil_mean, soil_cov)\ntrain_eucl_dist = euclidean_distance(train_features, soil_mean)\ntrain_cosine_sim = cosine_similarity_score(train_features, soil_mean)\n\nval_mahal_dist = mahalanobis_distance(val_features, soil_mean, soil_cov)\nval_eucl_dist = euclidean_distance(val_features, soil_mean)\nval_cosine_sim = cosine_similarity_score(val_features, soil_mean)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:52:52.506615Z","iopub.execute_input":"2025-05-24T10:52:52.506895Z","iopub.status.idle":"2025-05-24T10:52:52.617906Z","shell.execute_reply.started":"2025-05-24T10:52:52.506874Z","shell.execute_reply":"2025-05-24T10:52:52.617240Z"}},"outputs":[{"name":"stdout","text":"\nüìè Computing baseline distances on training data...\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# Compute thresholds (95th percentile of training distances)\nmahal_threshold = np.percentile(train_mahal_dist, 95)\neucl_threshold = np.percentile(train_eucl_dist, 95)\ncosine_threshold = np.percentile(train_cosine_sim, 5) ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:53:07.463704Z","iopub.execute_input":"2025-05-24T10:53:07.464384Z","iopub.status.idle":"2025-05-24T10:53:07.470836Z","shell.execute_reply.started":"2025-05-24T10:53:07.464365Z","shell.execute_reply":"2025-05-24T10:53:07.469997Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"print(f\"\\n Computed thresholds:\")\nprint(f\"   Mahalanobis threshold: {mahal_threshold:.4f}\")\nprint(f\"   Euclidean threshold: {eucl_threshold:.4f}\")\nprint(f\"   Cosine similarity threshold: {cosine_threshold:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:53:10.479400Z","iopub.execute_input":"2025-05-24T10:53:10.479708Z","iopub.status.idle":"2025-05-24T10:53:10.484127Z","shell.execute_reply.started":"2025-05-24T10:53:10.479687Z","shell.execute_reply":"2025-05-24T10:53:10.483417Z"}},"outputs":[{"name":"stdout","text":"\nüéØ Computed thresholds:\n   Mahalanobis threshold: 30.8685\n   Euclidean threshold: 6.6573\n   Cosine similarity threshold: 0.5514\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"class SoilAnomalyDetector:\n    def __init__(self, feature_extractor, soil_mean, soil_cov, thresholds):\n        self.feature_extractor = feature_extractor\n        self.soil_mean = soil_mean\n        self.soil_cov = soil_cov\n        self.mahal_threshold = thresholds['mahalanobis']\n        self.eucl_threshold = thresholds['euclidean']\n        self.cosine_threshold = thresholds['cosine']\n    \n    def extract_features(self, images):\n        \"\"\"Extract features from images\"\"\"\n        return self.feature_extractor.predict(images, batch_size=32, verbose=0)\n    \n    def compute_anomaly_scores(self, features):\n        \"\"\"Compute multiple anomaly scores\"\"\"\n        # Mahalanobis distance (normalized)\n        mahal_dist = mahalanobis_distance(features, self.soil_mean, self.soil_cov)\n        mahal_scores = mahal_dist / self.mahal_threshold\n        \n        # Euclidean distance (normalized)  \n        eucl_dist = euclidean_distance(features, self.soil_mean)\n        eucl_scores = eucl_dist / self.eucl_threshold\n        \n        # Cosine similarity (inverted and normalized)\n        cosine_sim = cosine_similarity_score(features, self.soil_mean)\n        cosine_scores = (self.cosine_threshold - cosine_sim) / self.cosine_threshold\n        \n        return mahal_scores, eucl_scores, cosine_scores\n    \n    def predict(self, images):\n        \"\"\"Predict if images are soil (1) or non-soil (0)\"\"\"\n        features = self.extract_features(images)\n        mahal_scores, eucl_scores, cosine_scores = self.compute_anomaly_scores(features)\n        \n        # Ensemble scoring (weighted average)\n        ensemble_scores = (0.4 * mahal_scores + 0.4 * eucl_scores + 0.2 * cosine_scores)\n        \n        # Convert to probabilities (sigmoid-like function)\n        anomaly_probabilities = 1 / (1 + np.exp(-2 * (ensemble_scores - 1)))\n        \n        # Convert to soil probabilities (1 - anomaly_probability)\n        soil_probabilities = 1 - anomaly_probabilities\n        \n        # Binary predictions: 1 for soil, 0 for non-soil\n        predictions = (soil_probabilities > 0.5).astype(int)\n        \n        return predictions, soil_probabilities, {\n            'mahalanobis': mahal_scores,\n            'euclidean': eucl_scores, \n            'cosine': cosine_scores,\n            'ensemble': ensemble_scores\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:53:33.226621Z","iopub.execute_input":"2025-05-24T10:53:33.227300Z","iopub.status.idle":"2025-05-24T10:53:33.233979Z","shell.execute_reply.started":"2025-05-24T10:53:33.227280Z","shell.execute_reply":"2025-05-24T10:53:33.233395Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# Create anomaly detector\nthresholds = {\n    'mahalanobis': mahal_threshold,\n    'euclidean': eucl_threshold,\n    'cosine': cosine_threshold\n}\n\nanomaly_detector = SoilAnomalyDetector(\n    feature_extractor, soil_mean, soil_cov, thresholds\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:53:38.891229Z","iopub.execute_input":"2025-05-24T10:53:38.891975Z","iopub.status.idle":"2025-05-24T10:53:38.895452Z","shell.execute_reply.started":"2025-05-24T10:53:38.891951Z","shell.execute_reply":"2025-05-24T10:53:38.894844Z"}},"outputs":[],"execution_count":23},{"cell_type":"code","source":"#  Validate on soil images (should predict as soil = 1) \nprint(\"\\n Validating on soil images...\")\nval_predictions, val_probabilities, val_scores = anomaly_detector.predict(X_val)\n\nsoil_accuracy = np.mean(val_predictions)  # Should be close to 1 (high soil classification rate)\nprint(f\" Soil validation accuracy: {soil_accuracy:.4f} ({soil_accuracy*100:.2f}%)\")\nprint(f\"   Average soil probability: {np.mean(val_probabilities):.4f}\")\nprint(f\"   Soil images classified correctly: {np.sum(val_predictions)}/{len(val_predictions)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T10:53:48.965394Z","iopub.execute_input":"2025-05-24T10:53:48.965703Z","iopub.status.idle":"2025-05-24T10:53:49.930163Z","shell.execute_reply.started":"2025-05-24T10:53:48.965681Z","shell.execute_reply":"2025-05-24T10:53:49.929355Z"}},"outputs":[{"name":"stdout","text":"\nüß™ Validating on soil images...\n‚úÖ Soil validation accuracy: 0.7828 (78.28%)\n   Average soil probability: 0.5714\n   Soil images classified correctly: 191/244\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"#  Function to process test images and create submission \ndef create_submission(detector, test_dir, test_ids_path, output_csv='submission.csv'):\n    \"\"\"Process test images using test_ids.csv and create submission file\"\"\"\n    print(f\"\\nüîç Processing test images from: {test_dir}\")\n    print(f\"üìã Using test IDs from: {test_ids_path}\")\n    \n    # Load test IDs\n    try:\n        test_ids_df = pd.read_csv(test_ids_path)\n        print(f\"‚úÖ Loaded test_ids.csv with {len(test_ids_df)} entries\")\n        print(\"Sample test IDs:\")\n        print(test_ids_df.head())\n        \n        # Get the column name for image IDs\n        if 'image_id' in test_ids_df.columns:\n            test_files = test_ids_df['image_id'].tolist()\n        elif 'id' in test_ids_df.columns:\n            test_files = test_ids_df['id'].tolist()\n        else:\n            # Use the first column if standard names not found\n            test_files = test_ids_df.iloc[:, 0].tolist()\n            print(f\"Using column '{test_ids_df.columns[0]}' as image IDs\")\n            \n    except Exception as e:\n        print(f\"‚ùå Error loading test_ids.csv: {e}\")\n        return None\n    \n    if not os.path.exists(test_dir):\n        print(f\"‚ùå Test directory not found: {test_dir}\")\n        return None\n    \n    print(f\"üìä Processing {len(test_files)} test images from test_ids.csv\")\n    \n    # Process images in batches\n    batch_size = 32\n    all_predictions = []\n    all_probabilities = []\n    all_filenames = []\n    missing_files = []\n    \n    for i in range(0, len(test_files), batch_size):\n        batch_files = test_files[i:i+batch_size]\n        batch_images = []\n        batch_valid_files = []\n        \n        # Load batch images\n        for filename in batch_files:\n            try:\n                img_path = os.path.join(test_dir, filename)\n                \n                if not os.path.exists(img_path):\n                    print(f\"‚ö†Ô∏è  Missing file: {filename}\")\n                    missing_files.append(filename)\n                    # Add default prediction for missing files (predict as non-soil)\n                    all_predictions.append(0)\n                    all_probabilities.append(0.0)\n                    all_filenames.append(filename)\n                    continue\n                \n                img = Image.open(img_path).convert('RGB')\n                img = img.resize((224, 224), Image.Resampling.LANCZOS)\n                img_array = np.array(img, dtype=np.float32)\n                img_array = tf.keras.applications.efficientnet.preprocess_input(img_array)\n                \n                batch_images.append(img_array)\n                batch_valid_files.append(filename)\n                \n            except Exception as e:\n                print(f\"Error processing {filename}: {e}\")\n                # Add default prediction for corrupted files (predict as non-soil)\n                all_predictions.append(0)\n                all_probabilities.append(0.0)\n                all_filenames.append(filename)\n        \n        if len(batch_images) > 0:\n            batch_images = np.array(batch_images)\n            \n            # Make predictions\n            batch_preds, batch_probs, _ = detector.predict(batch_images)\n            \n            all_predictions.extend(batch_preds)\n            all_probabilities.extend(batch_probs)\n            all_filenames.extend(batch_valid_files)\n            \n            print(f\"   Processed batch {i//batch_size + 1}: {len(batch_images)} images\")\n    \n    # Ensure we have predictions for all test IDs\n    if len(all_predictions) != len(test_files):\n        print(f\"‚ö†Ô∏è  Mismatch: Expected {len(test_files)} predictions, got {len(all_predictions)}\")\n    \n    # Create submission DataFrame in the required format\n    submission_df = pd.DataFrame({\n        'image_id': test_files,  # Use original order from test_ids.csv\n        'label': all_predictions[:len(test_files)]  # Ensure matching length\n    })\n    \n    # Save submission file\n    submission_df.to_csv(output_csv, index=False)\n    print(f\"üíæ Submission file saved to: {output_csv}\")\n    \n    # Print summary\n    soil_count = sum(all_predictions[:len(test_files)])\n    non_soil_count = len(test_files) - soil_count\n    \n    print(f\"\\nüìà Submission Summary:\")\n    print(f\"   Total images in submission: {len(submission_df)}\")\n    print(f\"   Predicted as Soil (label=1): {soil_count} ({soil_count/len(submission_df)*100:.1f}%)\")\n    print(f\"   Predicted as Non-Soil (label=0): {non_soil_count} ({non_soil_count/len(submission_df)*100:.1f}%)\")\n    if len(all_probabilities) > 0:\n        print(f\"   Average soil probability: {np.mean(all_probabilities[:len(test_files)]):.4f}\")\n    if missing_files:\n        print(f\"   Missing/corrupted files: {len(missing_files)}\")\n    \n    # Show sample of submission format\n    print(f\"\\nüìã Sample submission format:\")\n    print(submission_df.head(10))\n    print(\"...\")\n    print(submission_df.tail(5))\n    \n    # Verify submission format\n    print(f\"\\n‚úÖ Submission file validation:\")\n    print(f\"   Shape: {submission_df.shape}\")\n    print(f\"   Columns: {list(submission_df.columns)}\")\n    print(f\"   Label distribution: {submission_df['label'].value_counts().to_dict()}\")\n    print(f\"   No missing values: {not submission_df.isnull().any().any()}\")\n    \n    return submission_df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T11:05:21.967821Z","iopub.execute_input":"2025-05-24T11:05:21.968537Z","iopub.status.idle":"2025-05-24T11:05:21.988856Z","shell.execute_reply.started":"2025-05-24T11:05:21.968508Z","shell.execute_reply":"2025-05-24T11:05:21.988139Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"#  Create submission file \nsubmission_results = create_submission(anomaly_detector, TEST_IMAGE_DIR, TEST_IDS_PATH, 'submission.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T11:05:36.978066Z","iopub.execute_input":"2025-05-24T11:05:36.978728Z","iopub.status.idle":"2025-05-24T11:05:55.077832Z","shell.execute_reply.started":"2025-05-24T11:05:36.978705Z","shell.execute_reply":"2025-05-24T11:05:55.077133Z"}},"outputs":[{"name":"stdout","text":"\nüîç Processing test images from: /kaggle/input/soil-classification-part-2/soil_competition-2025/test\nüìã Using test IDs from: /kaggle/input/soil-classification-part-2/soil_competition-2025/test_ids.csv\n‚úÖ Loaded test_ids.csv with 967 entries\nSample test IDs:\n                               image_id\n0  6595f1266325552489c7d1635fafb88f.jpg\n1  4b614841803d5448b59e2c6ca74ea664.jpg\n2  ca30e008692a50638b43d944f46245c8.jpg\n3  6a9046a219425f7599729be627df1c1a.jpg\n4  97c1e0276d2d5c2f88dddbc87357611e.jpg\nüìä Processing 967 test images from test_ids.csv\n   Processed batch 1: 32 images\n   Processed batch 2: 32 images\n   Processed batch 3: 32 images\n   Processed batch 4: 32 images\n   Processed batch 5: 32 images\n   Processed batch 6: 32 images\n   Processed batch 7: 32 images\n   Processed batch 8: 32 images\n   Processed batch 9: 32 images\n   Processed batch 10: 32 images\n   Processed batch 11: 32 images\n   Processed batch 12: 32 images\n   Processed batch 13: 32 images\n   Processed batch 14: 32 images\n   Processed batch 15: 32 images\n   Processed batch 16: 32 images\n   Processed batch 17: 32 images\n   Processed batch 18: 32 images\n   Processed batch 19: 32 images\n   Processed batch 20: 32 images\n   Processed batch 21: 32 images\n   Processed batch 22: 32 images\n   Processed batch 23: 32 images\n   Processed batch 24: 32 images\n   Processed batch 25: 32 images\n   Processed batch 26: 32 images\n   Processed batch 27: 32 images\n   Processed batch 28: 32 images\n   Processed batch 29: 32 images\n   Processed batch 30: 32 images\n   Processed batch 31: 7 images\nüíæ Submission file saved to: submission.csv\n\nüìà Submission Summary:\n   Total images in submission: 967\n   Predicted as Soil (label=1): 271 (28.0%)\n   Predicted as Non-Soil (label=0): 696 (72.0%)\n   Average soil probability: 0.1945\n\nüìã Sample submission format:\n                               image_id  label\n0  6595f1266325552489c7d1635fafb88f.jpg      1\n1  4b614841803d5448b59e2c6ca74ea664.jpg      1\n2  ca30e008692a50638b43d944f46245c8.jpg      1\n3  6a9046a219425f7599729be627df1c1a.jpg      1\n4  97c1e0276d2d5c2f88dddbc87357611e.jpg      1\n5  e432d7988d125c8497d41b7ff223b187.jpg      1\n6  0821ca8d9d405e02ab9ebe34ac53d6bd.jpg      1\n7  a618ea007b745f56a992eec9f88804f0.jpg      1\n8  58e189dd45a156c7934344242452fad4.jpg      1\n9  21cdc53949d851b68191e560601e6e0c.jpg      0\n...\n                                 image_id  label\n962  0a7bf5babc365ca6b10dae582661988e.jpg      0\n963  1bd2aef3edff5434891801e77975f533.jpg      0\n964  86522810b6045b2f9ccdb2f9027aadf8.jpg      0\n965  687517ac929e59428f0c20de4a994b5f.jpg      0\n966  3325701afb3b52e1871d401e2a3cf0a3.jpg      0\n\n‚úÖ Submission file validation:\n   Shape: (967, 2)\n   Columns: ['image_id', 'label']\n   Label distribution: {0: 696, 1: 271}\n   No missing values: True\n","output_type":"stream"}],"execution_count":31},{"cell_type":"code","source":"#  Save the complete model \ndef save_soil_detector(detector, save_path='soil_anomaly_detector'):\n    \"\"\"Save the complete anomaly detector\"\"\"\n    \n    # Save feature extractor\n    detector.feature_extractor.save(f'{save_path}_feature_extractor.h5')\n    \n    # Save soil statistics and thresholds\n    np.savez(f'{save_path}_parameters.npz',\n             soil_mean=detector.soil_mean,\n             soil_cov=detector.soil_cov,\n             mahal_threshold=detector.mahal_threshold,\n             eucl_threshold=detector.eucl_threshold,\n             cosine_threshold=detector.cosine_threshold)\n    \n    print(f\"üíæ Complete detector saved:\")\n    print(f\"   Feature extractor: {save_path}_feature_extractor.h5\")\n    print(f\"   Parameters: {save_path}_parameters.npz\")\n\nsave_soil_detector(anomaly_detector)\n\nprint(f\"\\nüéØ One-Class Soil Detection Complete!\")\nprint(f\"   Approach: Anomaly Detection (One-Class Classification)\")\nprint(f\"   Training: Only soil images used\")\nprint(f\"   Testing: Detects deviations from soil patterns\")\nprint(f\"   Validation accuracy on soil: {soil_accuracy:.4f} ({soil_accuracy*100:.2f}%)\")\n\nif submission_results is not None:\n    print(f\"   Submission file created: submission.csv\")\n    print(f\"   Format: image_id, label (1=soil, 0=non-soil)\")\n    total_images = len(submission_results)\n    soil_predictions = sum(submission_results['label'])\n    print(f\"   Predicted {soil_predictions}/{total_images} images as soil\")\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T11:06:11.337104Z","iopub.execute_input":"2025-05-24T11:06:11.337389Z","iopub.status.idle":"2025-05-24T11:06:11.871928Z","shell.execute_reply.started":"2025-05-24T11:06:11.337367Z","shell.execute_reply":"2025-05-24T11:06:11.871240Z"}},"outputs":[{"name":"stdout","text":"üíæ Complete detector saved:\n   Feature extractor: soil_anomaly_detector_feature_extractor.h5\n   Parameters: soil_anomaly_detector_parameters.npz\n\nüéØ One-Class Soil Detection Complete!\n   Approach: Anomaly Detection (One-Class Classification)\n   Training: Only soil images used\n   Testing: Detects deviations from soil patterns\n   Validation accuracy on soil: 0.7828 (78.28%)\n   Submission file created: submission.csv\n   Format: image_id, label (1=soil, 0=non-soil)\n   Predicted 271/967 images as soil\n","output_type":"stream"}],"execution_count":32},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}